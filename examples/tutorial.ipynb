{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime-Switching Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`regime_switch_model` is a set of algorithms for learning and inference on regime-switching model. Let $y_t$ be a $p\\times 1$ observed time series and $h_t$ be a homogenous and stationary hidden Markov\n",
    "chain taking values in $\\{1, 2, \\dots, m\\}$ with transition probabilities\n",
    "    \\begin{equation}\n",
    "    w_{kj} = P(h_{t+1}=j\\mid h_t=k), \\quad k,j=1, \\dots, m\n",
    "    \\end{equation}\n",
    "where the number of hidden states $m$ is known. It is assumed that the financial market in\n",
    "each period can be realized as one of $m$ regime. Furthermore, the regimes are characterized\n",
    "by a set of $J$ risk factors, which represent broad macro and micro economic indicators. Let $F_{tj}$ be the value of the $j$th risk factor $(j=1, \\dots, J)$ in period $t$. Correspondingly, $F_t$ is the vector of risk factors in period $t$. We assumes that, for $t=1, \\dots, n$, when the market is in regime $h_t$ in period $t$,\n",
    "    \\begin{equation}\n",
    "    y_t = u_{h_t} + B_{h_t}F_t + \\Gamma_{h_t}\\epsilon_t,\n",
    "    \\end{equation}\n",
    "where $\\epsilon_t \\sim N(0,I)$. The model parameters $\\{u_{h_t}, B_{h_t}, \\Gamma_{h_t}\\}$ depend on the regime $h_t$. $u_{h_t}$ is the state-dependent intercepts of the linear factor model. The matrix $B_{h_t}$ defines the sensitivities of asset returns to the common risk factors in state $h_t$ and is often called the loading matrix.\n",
    "\n",
    "`regime_switch_model` solves the following fundamental problems:\n",
    "* Given the observed data, estimate the model parameters\n",
    "* Given the model parameters and observed data, estimate the optimal sequence of hidden states\n",
    "\n",
    "The implementation of code is based on the well-known Baum-Welch algorithm  and Viterbi algorithm that are widely used in hidden Markov model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from regime_switch_model.rshmm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate samples based on the regime-switching model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = HMMRS(n_components=2)\n",
    "# startprob\n",
    "model.startprob_ = np.array([0.9, 0.1])\n",
    "\n",
    "# transition matrix\n",
    "model.transmat_ = np.array([[0.9, 0.1], [0.6, 0.4]])\n",
    "# risk factor matrix\n",
    "# read file from Fama-French three-factor data\n",
    "Fama_French = pd.read_csv('Global_ex_US_3_Factors_Daily.csv', skiprows=3)\n",
    "Fama_French.rename(columns={'Unnamed: 0': 'TimeStamp'}, inplace=True)\n",
    "Fama_French.replace(-99.99, np.nan);\n",
    "Fama_French.replace(-999, np.nan);\n",
    "\n",
    "# select data \n",
    "#Fama_French_subset = Fama_French[(Fama_French['TimeStamp'] >= 20150101) & (Fama_French['TimeStamp'] <= 20171231)]\n",
    "Fama_French_subset = Fama_French\n",
    "Fama_French_subset.drop(['TimeStamp', 'RF'], axis=1, inplace=True)\n",
    "F = np.hstack((np.atleast_2d(np.ones(Fama_French_subset.shape[0])).T, Fama_French_subset))\n",
    "\n",
    "# loading matrix with intercept\n",
    "loadingmat1 = np.array([[0.9, 0.052, -0.02], \n",
    "                        [0.3, 0.27, 0.01], \n",
    "                        [0.12, 0.1, -0.05], \n",
    "                        [0.04, 0.01, -0.15], \n",
    "                        [0.15, 0.04, -0.11]])\n",
    "intercept1 = np.atleast_2d(np.array([-0.015, -0.01, 0.005, 00.1, 0.02])).T\n",
    "\n",
    "model.loadingmat_ = np.stack((np.hstack((intercept1, loadingmat1)), \n",
    "                              np.hstack((0.25*intercept1, -0.5* loadingmat1))), axis=0)\n",
    "\n",
    "# covariance matrix\n",
    "n_stocks = 5\n",
    "rho = 0.2\n",
    "Sigma1 = np.full((n_stocks, n_stocks), rho) + np.diag(np.repeat(1-rho, n_stocks))\n",
    "model.covmat_ = np.stack((Sigma1, 10*Sigma1), axis=0)\n",
    "\n",
    "save = True\n",
    "# sample\n",
    "Y, Z = model.sample(F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Split data into training and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use the last 300 day as the test data\n",
    "Y_train = Y[:-300,:]\n",
    "Y_test = Y[-300:,:]\n",
    "F_train = F[:-300,:]\n",
    "F_test = F[-300:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fitting Regime-Switch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -63535.1590              nan\n",
      "         2      -60972.1968        2562.9622\n",
      "         3      -59533.7367        1438.4601\n",
      "         4      -56005.9127        3527.8240\n",
      "         5      -54584.0500        1421.8628\n",
      "         6      -54259.0186         325.0314\n",
      "         7      -54199.8384          59.1802\n",
      "         8      -54192.7580           7.0804\n",
      "         9      -54192.0477           0.7103\n",
      "        10      -54191.9793           0.0684\n",
      "        11      -54191.9727           0.0065\n",
      "        12      -54191.9721           0.0006\n",
      "        13      -54191.9720           0.0001\n"
     ]
    }
   ],
   "source": [
    "remodel = HMMRS(n_components=2, verbose=True)\n",
    "remodel.fit(Y_train, F_train)\n",
    "Z2, logl, viterbi_lattice = remodel.predict(Y_train, F_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Examine model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of data points = ', 6723)\n",
      " \n",
      "Starting probability\n",
      "[  1.78e-13   1.00e+00]\n",
      " \n",
      "Transition matrix\n",
      "[[ 0.37  0.63]\n",
      " [ 0.11  0.89]]\n",
      " \n",
      "Means and vars of each hidden state\n",
      "0th hidden state\n",
      "('loading matrix = ', array([[-0.14, -0.53, -0.15, -0.03],\n",
      "       [-0.04, -0.04, -0.17,  0.06],\n",
      "       [ 0.04, -0.15, -0.23, -0.02],\n",
      "       [ 0.02,  0.02,  0.19, -0.  ],\n",
      "       [ 0.01,  0.07, -0.04,  0.24]]))\n",
      "('covariance = ', array([[ 10.55,   1.92,   2.14,   1.56,   1.37],\n",
      "       [  1.92,   9.53,   1.68,   2.19,   1.74],\n",
      "       [  2.14,   1.68,   9.44,   1.85,   1.71],\n",
      "       [  1.56,   2.19,   1.85,   9.89,   2.62],\n",
      "       [  1.37,   1.74,   1.71,   2.62,  10.24]]))\n",
      " \n",
      "1th hidden state\n",
      "('loading matrix = ', array([[ -6.79e-03,   8.93e-01,   3.71e-02,   4.66e-02],\n",
      "       [ -2.98e-02,   2.93e-01,   2.42e-01,   1.15e-01],\n",
      "       [  7.01e-04,   1.09e-01,   6.24e-02,  -2.15e-02],\n",
      "       [  9.63e-02,   4.09e-02,  -1.29e-02,  -1.78e-01],\n",
      "       [  1.62e-02,   1.48e-01,  -2.12e-04,  -1.60e-01]]))\n",
      "('covariance = ', array([[ 0.98,  0.2 ,  0.24,  0.19,  0.2 ],\n",
      "       [ 0.2 ,  0.98,  0.21,  0.21,  0.17],\n",
      "       [ 0.24,  0.21,  1.01,  0.19,  0.21],\n",
      "       [ 0.19,  0.21,  0.19,  0.94,  0.19],\n",
      "       [ 0.2 ,  0.17,  0.21,  0.19,  0.98]]))\n",
      " \n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Number of data points = \", Y_train.shape[0])\n",
    "print(\" \")\n",
    "print(\"Starting probability\")\n",
    "print(remodel.startprob_)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Transition matrix\")\n",
    "print(remodel.transmat_)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Means and vars of each hidden state\")\n",
    "for i in range(remodel.n_components):\n",
    "    print(\"{0}th hidden state\".format(i))\n",
    "    print(\"loading matrix = \", remodel.loadingmat_[i])\n",
    "    print(\"covariance = \", remodel.covmat_[i])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Examine the predicted hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Prediction accuracy of the hidden states = ', 0.9840844860925182)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction accuracy of the hidden states = \", np.mean(np.equal(Z[:-300], 1-Z2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
